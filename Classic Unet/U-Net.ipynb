{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook demostrates the implementation of a Unet Architecture as mentioned on the Original Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Basic Unet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a input layer\n",
    "inputs = tf.keras.layers.Input((128,128,3))\n",
    "\n",
    "# Rescaling the image input to the range of 0-1\n",
    "inp = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "# The encoding layers\n",
    "# Encoding is performed by successive convolution layer followed by a Max Pooling Layer to reduce the spatial resolution (Downsample the Image)\n",
    "\n",
    "# Weights of the convolution kernels are initialized based on normal distribution, these kernel weights will be updated during the model training \n",
    "# The Encoding Path Consists of 4 successive convolution blocks as implemented below\n",
    "\n",
    "# First convolution block\n",
    "c1 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(inp)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "# Second covolution block\n",
    "c2 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(p1)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "# Third covolution block\n",
    "c3 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(p2)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "# Forth covolution block\n",
    "c4 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(p3)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "# A bridge is needed to connect the Encoder block to the Decoder block, here a convolution layer is used to create a bridge connection\n",
    "c5 = tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(p4)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c5)\n",
    "\n",
    "# Decoding is performed by up-sampling, concatination of the upsampled layer to the corresponding convolution layer of the encoder and then performing convolution operation on the concatinated output\n",
    "# The Encoder and Decoder have the same number of building blocks\n",
    "\n",
    "# First Decoding Layer \n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding = 'same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6,c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(u6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c6)\n",
    "\n",
    "# Second Decoding Layer\n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding = 'same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7,c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(u7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c7)\n",
    "\n",
    "# Third Decoding Layer\n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding = 'same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8,c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(u8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c8)\n",
    "\n",
    "# Fourth Decoding Layer\n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding = 'same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9,c1])\n",
    "c9 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(u9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(c9)\n",
    "\n",
    "# Finally the output layer will be a 1*1 convolution to create a mask which is equal in size to the original image, the mask generated by the output layer is a binary mask and sigmoid activation function is used, a softmax function could also be used but will require extra steps to conver the generated mask to a binarized form\n",
    "output = tf.keras.layers.Conv2D(1, (1,1), activation = 'sigmoid')(c9)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Defined Model will be trained on a sample dataset publicly available on Kaggle, the link for the dataset is on the repo description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed is defined for the repeatiability of the respective opeation\n",
    "seed = 42\n",
    "np.random.seed = seed\n",
    "\n",
    "# These will be used to rescale the image to fit the model input requirements\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "#train and test path of the images, this is defined according to path mentioned on the dataset\n",
    "TRAIN_PATH = 'data-science-bowl-2018/stage1_train/'\n",
    "TEST_PATH = 'data-science-bowl-2018/stage1_test/'\n",
    "\n",
    "# Create a iterator to scan in folder for files and subfolders\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "#creating empty numpy arrays, each file is read and the array is updated according, the final array will have a size of (128, 128, 3, N) for the trainign images, N being the number of images loaded\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)\n",
    "\n",
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img  #Fill empty X_train with values from img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)\n",
    "\n",
    "    # In the dataset same image has multiple mask with one mask file containing one segmented part, this combines all the mask to a single mask\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)  \n",
    "            \n",
    "    Y_train[n] = mask   \n",
    "\n",
    "# Creating test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Resizing test images') \n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "\n",
    "#Printing out sample images from the prepared dataset\n",
    "image_x = random.randint(0, len(train_ids))\n",
    "imshow(X_train[image_x])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[image_x]))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[inputs], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0])])\n",
    "\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=25)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating prediction on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(X_train))\n",
    "\n",
    "\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    " \n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "imshow(np.squeeze(preds_val_t[ix]), alpha=0.1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctbone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
